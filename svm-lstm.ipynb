{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNS2pPByD3COfPFZmMmbVS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanjeda039/Biodata_Laravel/blob/main/svm-lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrYhOK_6uf03",
        "outputId": "535a41dd-856c-40d6-8dd0-603abfbb0e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataset  (6252, 2)\n",
            "Index(['Type', 'normalized_requirements'], dtype='object')\n",
            "No. of unique classes 12\n",
            "Number of Unique Tokens 1554\n",
            "Shape of Data Tensor: (6252, 1000)\n",
            "Shape of Label Tensor: (6252, 12)\n",
            "\n",
            "Fold 1\n",
            "Total 4894 word vectors in Glove 6B 100d.\n",
            "Hybrid LSTM-SVM Model\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 1000, 100)         155500    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 200)               160800    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                612       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326962 (1.25 MB)\n",
            "Trainable params: 326962 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.4827\n",
            "Epoch 1: val_accuracy improved from -inf to 0.77058, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 142s 70ms/step - loss: 0.1524 - accuracy: 0.4827 - val_loss: 0.0991 - val_accuracy: 0.7706\n",
            "Epoch 2/15\n",
            "   2/1875 [..............................] - ETA: 1:44 - loss: 0.2174 - accuracy: 0.5000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.8424\n",
            "Epoch 2: val_accuracy improved from 0.77058 to 0.90967, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0657 - accuracy: 0.8424 - val_loss: 0.0405 - val_accuracy: 0.9097\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9432\n",
            "Epoch 3: val_accuracy improved from 0.90967 to 0.94005, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0275 - accuracy: 0.9432 - val_loss: 0.0232 - val_accuracy: 0.9400\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9736\n",
            "Epoch 4: val_accuracy improved from 0.94005 to 0.97362, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 132s 71ms/step - loss: 0.0143 - accuracy: 0.9736 - val_loss: 0.0157 - val_accuracy: 0.9736\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9859\n",
            "Epoch 5: val_accuracy did not improve from 0.97362\n",
            "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0082 - accuracy: 0.9859 - val_loss: 0.0173 - val_accuracy: 0.9600\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9915\n",
            "Epoch 6: val_accuracy improved from 0.97362 to 0.98082, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0053 - accuracy: 0.9915 - val_loss: 0.0091 - val_accuracy: 0.9808\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9941\n",
            "Epoch 7: val_accuracy improved from 0.98082 to 0.98161, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0037 - accuracy: 0.9941 - val_loss: 0.0082 - val_accuracy: 0.9816\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9957\n",
            "Epoch 8: val_accuracy did not improve from 0.98161\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0023 - accuracy: 0.9957 - val_loss: 0.0085 - val_accuracy: 0.9808\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9984\n",
            "Epoch 9: val_accuracy improved from 0.98161 to 0.98241, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 0.0080 - val_accuracy: 0.9824\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9984\n",
            "Epoch 10: val_accuracy did not improve from 0.98241\n",
            "1875/1875 [==============================] - 127s 67ms/step - loss: 0.0014 - accuracy: 0.9984 - val_loss: 0.0091 - val_accuracy: 0.9824\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9987\n",
            "Epoch 11: val_accuracy improved from 0.98241 to 0.98481, saving model to model_rnn_fold_1.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0011 - accuracy: 0.9987 - val_loss: 0.0063 - val_accuracy: 0.9848\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 6.7523e-04 - accuracy: 0.9995\n",
            "Epoch 12: val_accuracy did not improve from 0.98481\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 6.7523e-04 - accuracy: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9848\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 5.0341e-04 - accuracy: 0.9995\n",
            "Epoch 13: val_accuracy did not improve from 0.98481\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 5.0341e-04 - accuracy: 0.9995 - val_loss: 0.0072 - val_accuracy: 0.9840\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 5.5151e-04 - accuracy: 0.9992\n",
            "Epoch 14: val_accuracy did not improve from 0.98481\n",
            "1875/1875 [==============================] - 134s 72ms/step - loss: 5.5151e-04 - accuracy: 0.9992 - val_loss: 0.0106 - val_accuracy: 0.9784\n",
            "40/40 [==============================] - 2s 26ms/step\n",
            "\n",
            "Fold Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.99      1.00      1.00       104\n",
            "          FR       0.97      0.85      0.90       104\n",
            "          FT       1.00      1.00      1.00       104\n",
            "           L       1.00      1.00      1.00       104\n",
            "          LF       0.98      1.00      0.99       105\n",
            "          MN       1.00      1.00      1.00       105\n",
            "           O       0.98      1.00      0.99       104\n",
            "          PE       1.00      1.00      1.00       104\n",
            "          PO       1.00      1.00      1.00       105\n",
            "          SC       1.00      1.00      1.00       104\n",
            "          SE       0.96      0.97      0.97       104\n",
            "          US       0.94      1.00      0.97       104\n",
            "\n",
            "    accuracy                           0.98      1251\n",
            "   macro avg       0.98      0.98      0.98      1251\n",
            "weighted avg       0.98      0.98      0.98      1251\n",
            "\n",
            "\n",
            "Training Metrics: Accuracy: 0.9997333288192749\n",
            "Validation Metrics: Accuracy: 0.9848121404647827\n",
            "Testing Metrics: Accuracy: 0.9848121404647827\n",
            "\n",
            "Training Confusion Matrix:\n",
            "118/118 [==============================] - 3s 26ms/step\n",
            "[[312   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 311   0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   0 313   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 313   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 312   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 312   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 312   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 313   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 312   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 313   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 313   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 313]]\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "40/40 [==============================] - 1s 26ms/step\n",
            "[[105   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  88   0   2   4   1   2   1   0   0   2   5]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 104   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 104   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 105   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 104   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0 102   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[104   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1  88   0   0   2   0   2   0   0   0   4   7]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 105   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 104   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 105   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   3   0   0   0   0   0   0   0   0 101   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Fold 2\n",
            "Total 195694 word vectors in Glove 6B 100d.\n",
            "Hybrid LSTM-SVM Model\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 1000, 100)         155500    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 200)               160800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 12)                612       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326962 (1.25 MB)\n",
            "Trainable params: 326962 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.5904\n",
            "Epoch 1: val_accuracy improved from -inf to 0.83693, saving model to model_rnn_fold_2.hdf5\n",
            "1875/1875 [==============================] - 133s 70ms/step - loss: 0.1311 - accuracy: 0.5904 - val_loss: 0.0744 - val_accuracy: 0.8369\n",
            "Epoch 2/15\n",
            "   2/1875 [..............................] - ETA: 1:48 - loss: 0.0822 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9069\n",
            "Epoch 2: val_accuracy improved from 0.83693 to 0.95124, saving model to model_rnn_fold_2.hdf5\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0434 - accuracy: 0.9069 - val_loss: 0.0223 - val_accuracy: 0.9512\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9669\n",
            "Epoch 3: val_accuracy improved from 0.95124 to 0.96723, saving model to model_rnn_fold_2.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0168 - accuracy: 0.9669 - val_loss: 0.0192 - val_accuracy: 0.9672\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9824\n",
            "Epoch 4: val_accuracy improved from 0.96723 to 0.98161, saving model to model_rnn_fold_2.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0096 - accuracy: 0.9824 - val_loss: 0.0086 - val_accuracy: 0.9816\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9891\n",
            "Epoch 5: val_accuracy improved from 0.98161 to 0.98241, saving model to model_rnn_fold_2.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0058 - accuracy: 0.9891 - val_loss: 0.0079 - val_accuracy: 0.9824\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9944\n",
            "Epoch 6: val_accuracy improved from 0.98241 to 0.98961, saving model to model_rnn_fold_2.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0035 - accuracy: 0.9944 - val_loss: 0.0063 - val_accuracy: 0.9896\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9957\n",
            "Epoch 7: val_accuracy did not improve from 0.98961\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0025 - accuracy: 0.9957 - val_loss: 0.0119 - val_accuracy: 0.9840\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9965\n",
            "Epoch 8: val_accuracy did not improve from 0.98961\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0019 - accuracy: 0.9965 - val_loss: 0.0075 - val_accuracy: 0.9840\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9979\n",
            "Epoch 9: val_accuracy did not improve from 0.98961\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0012 - accuracy: 0.9979 - val_loss: 0.0069 - val_accuracy: 0.9872\n",
            "40/40 [==============================] - 2s 26ms/step\n",
            "\n",
            "Fold Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.99      1.00      1.00       104\n",
            "          FR       1.00      0.84      0.91       104\n",
            "          FT       1.00      1.00      1.00       104\n",
            "           L       1.00      1.00      1.00       104\n",
            "          LF       0.96      1.00      0.98       105\n",
            "          MN       0.99      1.00      1.00       105\n",
            "           O       0.99      1.00      1.00       104\n",
            "          PE       0.98      1.00      0.99       104\n",
            "          PO       1.00      1.00      1.00       105\n",
            "          SC       1.00      1.00      1.00       104\n",
            "          SE       1.00      0.97      0.99       104\n",
            "          US       0.90      1.00      0.95       104\n",
            "\n",
            "    accuracy                           0.98      1251\n",
            "   macro avg       0.99      0.98      0.98      1251\n",
            "weighted avg       0.99      0.98      0.98      1251\n",
            "\n",
            "\n",
            "Training Metrics: Accuracy: 0.9981333613395691\n",
            "Validation Metrics: Accuracy: 0.9896082878112793\n",
            "Testing Metrics: Accuracy: 0.9840127825737\n",
            "\n",
            "Training Confusion Matrix:\n",
            "118/118 [==============================] - 3s 23ms/step\n",
            "[[312   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 305   0   0   1   0   0   1   0   0   3   2]\n",
            " [  0   0 313   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 313   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 312   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 312   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 312   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 313   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 312   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 313   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 313   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 313]]\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "40/40 [==============================] - 1s 26ms/step\n",
            "[[105   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  94   0   0   2   1   1   2   0   0   1   4]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 104   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 104   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 105   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 104   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 102   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[104   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1  87   0   0   4   1   1   2   0   0   0   8]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 105   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 104   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 105   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 101   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Fold 3\n",
            "Total 301592 word vectors in Glove 6B 100d.\n",
            "Hybrid LSTM-SVM Model\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 1000, 100)         155500    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 200)               160800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 12)                612       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326962 (1.25 MB)\n",
            "Trainable params: 326962 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.5568\n",
            "Epoch 1: val_accuracy improved from -inf to 0.82414, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 134s 70ms/step - loss: 0.1349 - accuracy: 0.5568 - val_loss: 0.0726 - val_accuracy: 0.8241\n",
            "Epoch 2/15\n",
            "   2/1875 [..............................] - ETA: 1:47 - loss: 0.0025 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.8952\n",
            "Epoch 2: val_accuracy improved from 0.82414 to 0.94085, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0472 - accuracy: 0.8952 - val_loss: 0.0249 - val_accuracy: 0.9408\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9651\n",
            "Epoch 3: val_accuracy improved from 0.94085 to 0.95923, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0175 - accuracy: 0.9651 - val_loss: 0.0201 - val_accuracy: 0.9592\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9811\n",
            "Epoch 4: val_accuracy improved from 0.95923 to 0.98002, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0099 - accuracy: 0.9811 - val_loss: 0.0111 - val_accuracy: 0.9800\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9891\n",
            "Epoch 5: val_accuracy improved from 0.98002 to 0.98481, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 134s 72ms/step - loss: 0.0057 - accuracy: 0.9891 - val_loss: 0.0072 - val_accuracy: 0.9848\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9941\n",
            "Epoch 6: val_accuracy improved from 0.98481 to 0.99041, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0034 - accuracy: 0.9941 - val_loss: 0.0055 - val_accuracy: 0.9904\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9968\n",
            "Epoch 7: val_accuracy did not improve from 0.99041\n",
            "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0021 - accuracy: 0.9968 - val_loss: 0.0071 - val_accuracy: 0.9856\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9979\n",
            "Epoch 8: val_accuracy did not improve from 0.99041\n",
            "1875/1875 [==============================] - 134s 72ms/step - loss: 0.0013 - accuracy: 0.9979 - val_loss: 0.0064 - val_accuracy: 0.9888\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy improved from 0.99041 to 0.99121, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0010 - accuracy: 0.9987 - val_loss: 0.0054 - val_accuracy: 0.9912\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 9.2402e-04 - accuracy: 0.9992\n",
            "Epoch 10: val_accuracy did not improve from 0.99121\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 9.2402e-04 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9880\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 5.5655e-04 - accuracy: 0.9992\n",
            "Epoch 11: val_accuracy improved from 0.99121 to 0.99440, saving model to model_rnn_fold_3.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 5.5655e-04 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9944\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 6.3194e-04 - accuracy: 0.9992\n",
            "Epoch 12: val_accuracy did not improve from 0.99440\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 6.3194e-04 - accuracy: 0.9992 - val_loss: 0.0055 - val_accuracy: 0.9912\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 5.3483e-04 - accuracy: 0.9995\n",
            "Epoch 13: val_accuracy did not improve from 0.99440\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 5.3483e-04 - accuracy: 0.9995 - val_loss: 0.0054 - val_accuracy: 0.9912\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 3.0440e-04 - accuracy: 0.9995\n",
            "Epoch 14: val_accuracy did not improve from 0.99440\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 3.0440e-04 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9896\n",
            "40/40 [==============================] - 2s 26ms/step\n",
            "\n",
            "Fold Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00       104\n",
            "          FR       1.00      0.88      0.94       104\n",
            "          FT       1.00      1.00      1.00       104\n",
            "           L       0.99      1.00      1.00       104\n",
            "          LF       0.99      1.00      1.00       105\n",
            "          MN       0.98      1.00      0.99       105\n",
            "           O       0.99      1.00      1.00       104\n",
            "          PE       0.97      1.00      0.99       104\n",
            "          PO       1.00      1.00      1.00       105\n",
            "          SC       1.00      1.00      1.00       104\n",
            "          SE       0.99      0.97      0.98       104\n",
            "          US       0.95      1.00      0.97       104\n",
            "\n",
            "    accuracy                           0.99      1251\n",
            "   macro avg       0.99      0.99      0.99      1251\n",
            "weighted avg       0.99      0.99      0.99      1251\n",
            "\n",
            "\n",
            "Training Metrics: Accuracy: 0.9997333288192749\n",
            "Validation Metrics: Accuracy: 0.9944044947624207\n",
            "Testing Metrics: Accuracy: 0.9880095720291138\n",
            "\n",
            "Training Confusion Matrix:\n",
            "118/118 [==============================] - 3s 27ms/step\n",
            "[[312   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 311   0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   0 313   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 313   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 312   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 312   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 312   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 313   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 312   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 313   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 313   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 313]]\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "40/40 [==============================] - 1s 25ms/step\n",
            "[[105   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 100   0   0   1   0   0   1   0   0   1   2]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 104   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 104   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 105   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 104   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 102   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[104   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  92   0   1   1   2   1   3   0   0   1   3]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 105   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 104   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 105   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 101   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Fold 4\n",
            "Total 399968 word vectors in Glove 6B 100d.\n",
            "Hybrid LSTM-SVM Model\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 1000, 100)         155500    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 200)               160800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 12)                612       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326962 (1.25 MB)\n",
            "Trainable params: 326962 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.5213\n",
            "Epoch 1: val_accuracy improved from -inf to 0.74021, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 134s 70ms/step - loss: 0.1482 - accuracy: 0.5213 - val_loss: 0.0897 - val_accuracy: 0.7402\n",
            "Epoch 2/15\n",
            "   2/1875 [..............................] - ETA: 1:54 - loss: 0.0387 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.8845\n",
            "Epoch 2: val_accuracy improved from 0.74021 to 0.94005, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0510 - accuracy: 0.8845 - val_loss: 0.0303 - val_accuracy: 0.9400\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9595\n",
            "Epoch 3: val_accuracy improved from 0.94005 to 0.94884, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0196 - accuracy: 0.9595 - val_loss: 0.0274 - val_accuracy: 0.9488\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9805\n",
            "Epoch 4: val_accuracy improved from 0.94884 to 0.97842, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0101 - accuracy: 0.9805 - val_loss: 0.0099 - val_accuracy: 0.9784\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9893\n",
            "Epoch 5: val_accuracy did not improve from 0.97842\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0061 - accuracy: 0.9893 - val_loss: 0.0186 - val_accuracy: 0.9576\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9933\n",
            "Epoch 6: val_accuracy improved from 0.97842 to 0.98241, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 136s 73ms/step - loss: 0.0039 - accuracy: 0.9933 - val_loss: 0.0076 - val_accuracy: 0.9824\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9955\n",
            "Epoch 7: val_accuracy improved from 0.98241 to 0.98481, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0024 - accuracy: 0.9955 - val_loss: 0.0075 - val_accuracy: 0.9848\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9965\n",
            "Epoch 8: val_accuracy improved from 0.98481 to 0.98561, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0020 - accuracy: 0.9965 - val_loss: 0.0070 - val_accuracy: 0.9856\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 8.6957e-04 - accuracy: 0.9987\n",
            "Epoch 9: val_accuracy improved from 0.98561 to 0.98801, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 130s 69ms/step - loss: 8.6957e-04 - accuracy: 0.9987 - val_loss: 0.0049 - val_accuracy: 0.9880\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy improved from 0.98801 to 0.98961, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0010 - accuracy: 0.9987 - val_loss: 0.0051 - val_accuracy: 0.9896\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 4.7999e-04 - accuracy: 0.9995\n",
            "Epoch 11: val_accuracy improved from 0.98961 to 0.99281, saving model to model_rnn_fold_4.hdf5\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 4.7999e-04 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9928\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 5.4542e-04 - accuracy: 0.9995\n",
            "Epoch 12: val_accuracy did not improve from 0.99281\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 5.4542e-04 - accuracy: 0.9995 - val_loss: 0.0063 - val_accuracy: 0.9864\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 4.2337e-04 - accuracy: 0.9995\n",
            "Epoch 13: val_accuracy did not improve from 0.99281\n",
            "1875/1875 [==============================] - 133s 71ms/step - loss: 4.2337e-04 - accuracy: 0.9995 - val_loss: 0.0042 - val_accuracy: 0.9904\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 2.7373e-04 - accuracy: 0.9997\n",
            "Epoch 14: val_accuracy did not improve from 0.99281\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 2.7373e-04 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 0.9904\n",
            "40/40 [==============================] - 2s 25ms/step\n",
            "\n",
            "Fold Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.99      1.00      1.00       104\n",
            "          FR       0.97      0.95      0.96       104\n",
            "          FT       1.00      1.00      1.00       104\n",
            "           L       1.00      1.00      1.00       104\n",
            "          LF       0.99      1.00      1.00       105\n",
            "          MN       1.00      1.00      1.00       105\n",
            "           O       0.99      1.00      1.00       104\n",
            "          PE       0.99      1.00      1.00       104\n",
            "          PO       1.00      1.00      1.00       105\n",
            "          SC       1.00      1.00      1.00       104\n",
            "          SE       1.00      0.97      0.99       104\n",
            "          US       0.99      1.00      1.00       104\n",
            "\n",
            "    accuracy                           0.99      1251\n",
            "   macro avg       0.99      0.99      0.99      1251\n",
            "weighted avg       0.99      0.99      0.99      1251\n",
            "\n",
            "\n",
            "Training Metrics: Accuracy: 0.9997333288192749\n",
            "Validation Metrics: Accuracy: 0.9928057789802551\n",
            "Testing Metrics: Accuracy: 0.9936051368713379\n",
            "\n",
            "Training Confusion Matrix:\n",
            "118/118 [==============================] - 3s 23ms/step\n",
            "[[312   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 311   0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   0 313   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 313   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 312   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 312   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 312   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 313   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 312   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 313   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 313   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 313]]\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "40/40 [==============================] - 1s 23ms/step\n",
            "[[105   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  98   0   0   1   1   2   1   0   0   0   2]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 104   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 104   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 105   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 104   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0 102   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[104   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1  99   0   0   1   0   1   1   0   0   0   1]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 105   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 104   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 105   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   3   0   0   0   0   0   0   0   0 101   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Fold 5\n",
            "Total 399968 word vectors in Glove 6B 100d.\n",
            "Hybrid LSTM-SVM Model\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 1000, 100)         155500    \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 200)               160800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 12)                612       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326962 (1.25 MB)\n",
            "Trainable params: 326962 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.5848\n",
            "Epoch 1: val_accuracy improved from -inf to 0.83613, saving model to model_rnn_fold_5.hdf5\n",
            "1875/1875 [==============================] - 133s 70ms/step - loss: 0.1324 - accuracy: 0.5848 - val_loss: 0.0707 - val_accuracy: 0.8361\n",
            "Epoch 2/15\n",
            "   2/1875 [..............................] - ETA: 1:45 - loss: 0.0656 - accuracy: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9077\n",
            "Epoch 2: val_accuracy improved from 0.83613 to 0.92886, saving model to model_rnn_fold_5.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0409 - accuracy: 0.9077 - val_loss: 0.0343 - val_accuracy: 0.9289\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9664\n",
            "Epoch 3: val_accuracy improved from 0.92886 to 0.97522, saving model to model_rnn_fold_5.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0169 - accuracy: 0.9664 - val_loss: 0.0113 - val_accuracy: 0.9752\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9824\n",
            "Epoch 4: val_accuracy improved from 0.97522 to 0.98161, saving model to model_rnn_fold_5.hdf5\n",
            "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0094 - accuracy: 0.9824 - val_loss: 0.0102 - val_accuracy: 0.9816\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9920\n",
            "Epoch 5: val_accuracy improved from 0.98161 to 0.98641, saving model to model_rnn_fold_5.hdf5\n",
            "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0051 - accuracy: 0.9920 - val_loss: 0.0083 - val_accuracy: 0.9864\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9952\n",
            "Epoch 6: val_accuracy did not improve from 0.98641\n",
            "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0030 - accuracy: 0.9952 - val_loss: 0.0085 - val_accuracy: 0.9816\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9968\n",
            "Epoch 7: val_accuracy did not improve from 0.98641\n",
            "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0019 - accuracy: 0.9968 - val_loss: 0.0067 - val_accuracy: 0.9832\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9979\n",
            "Epoch 8: val_accuracy did not improve from 0.98641\n",
            "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0015 - accuracy: 0.9979 - val_loss: 0.0101 - val_accuracy: 0.9792\n",
            "40/40 [==============================] - 2s 25ms/step\n",
            "\n",
            "Fold Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00       104\n",
            "          FR       0.97      0.87      0.91       104\n",
            "          FT       1.00      1.00      1.00       104\n",
            "           L       1.00      1.00      1.00       104\n",
            "          LF       0.99      1.00      1.00       105\n",
            "          MN       1.00      1.00      1.00       105\n",
            "           O       0.96      1.00      0.98       104\n",
            "          PE       0.94      0.98      0.96       104\n",
            "          PO       1.00      1.00      1.00       105\n",
            "          SC       1.00      1.00      1.00       104\n",
            "          SE       0.98      0.97      0.98       104\n",
            "          US       0.97      1.00      0.99       104\n",
            "\n",
            "    accuracy                           0.98      1251\n",
            "   macro avg       0.98      0.98      0.98      1251\n",
            "weighted avg       0.98      0.98      0.98      1251\n",
            "\n",
            "\n",
            "Training Metrics: Accuracy: 0.9936000108718872\n",
            "Validation Metrics: Accuracy: 0.9864108562469482\n",
            "Testing Metrics: Accuracy: 0.9848121404647827\n",
            "\n",
            "Training Confusion Matrix:\n",
            "118/118 [==============================] - 3s 23ms/step\n",
            "[[312   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 304   0   0   1   0   0   3   0   0   3   1]\n",
            " [  0   0 313   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 313   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 301   0  11   0   0   0   0   0]\n",
            " [  0   0   0   0   0 312   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 312   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 308   0   0   5   0]\n",
            " [  0   0   0   0   0   0   0   0 312   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 313   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 313   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 313]]\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "40/40 [==============================] - 1s 23ms/step\n",
            "[[105   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1  91   0   0   1   1   6   2   0   0   2   1]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 104   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 104   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 105   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 103   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0   0 104   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0 102   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[104   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  90   0   0   1   0   4   6   0   0   0   3]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 105   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 104   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 102   0   0   2   0]\n",
            " [  0   0   0   0   0   0   0   0 105   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   3   0   0   0   0   0   0   0   0 101   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Fold 6\n",
            "Total 399968 word vectors in Glove 6B 100d.\n",
            "Hybrid LSTM-SVM Model\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 1000, 100)         155500    \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 200)               160800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 12)                612       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326962 (1.25 MB)\n",
            "Trainable params: 326962 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.5552\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81135, saving model to model_rnn_fold_6.hdf5\n",
            "1875/1875 [==============================] - 134s 70ms/step - loss: 0.1388 - accuracy: 0.5552 - val_loss: 0.0896 - val_accuracy: 0.8114\n",
            "Epoch 2/15\n",
            "   2/1875 [..............................] - ETA: 1:45 - loss: 0.0629 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9019\n",
            "Epoch 2: val_accuracy improved from 0.81135 to 0.93685, saving model to model_rnn_fold_6.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0445 - accuracy: 0.9019 - val_loss: 0.0280 - val_accuracy: 0.9369\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9677\n",
            "Epoch 3: val_accuracy improved from 0.93685 to 0.95763, saving model to model_rnn_fold_6.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0171 - accuracy: 0.9677 - val_loss: 0.0231 - val_accuracy: 0.9576\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9861\n",
            "Epoch 4: val_accuracy improved from 0.95763 to 0.98241, saving model to model_rnn_fold_6.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0090 - accuracy: 0.9861 - val_loss: 0.0094 - val_accuracy: 0.9824\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9915\n",
            "Epoch 5: val_accuracy did not improve from 0.98241\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0050 - accuracy: 0.9915 - val_loss: 0.0077 - val_accuracy: 0.9800\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9944\n",
            "Epoch 6: val_accuracy did not improve from 0.98241\n",
            "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0031 - accuracy: 0.9944 - val_loss: 0.0111 - val_accuracy: 0.9776\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9965\n",
            "Epoch 7: val_accuracy improved from 0.98241 to 0.98481, saving model to model_rnn_fold_6.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0023 - accuracy: 0.9965 - val_loss: 0.0067 - val_accuracy: 0.9848\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9971\n",
            "Epoch 8: val_accuracy did not improve from 0.98481\n",
            "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0019 - accuracy: 0.9971 - val_loss: 0.0070 - val_accuracy: 0.9848\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9979\n",
            "Epoch 9: val_accuracy improved from 0.98481 to 0.98801, saving model to model_rnn_fold_6.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0012 - accuracy: 0.9979 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 9.7173e-04 - accuracy: 0.9987\n",
            "Epoch 10: val_accuracy improved from 0.98801 to 0.99121, saving model to model_rnn_fold_6.hdf5\n",
            "1875/1875 [==============================] - 136s 72ms/step - loss: 9.7173e-04 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 0.9912\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 5.3282e-04 - accuracy: 0.9995\n",
            "Epoch 11: val_accuracy did not improve from 0.99121\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 5.3282e-04 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9872\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 5.3460e-04 - accuracy: 0.9992\n",
            "Epoch 12: val_accuracy did not improve from 0.99121\n",
            "1875/1875 [==============================] - 128s 68ms/step - loss: 5.3460e-04 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9896\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 7.5073e-04 - accuracy: 0.9989\n",
            "Epoch 13: val_accuracy did not improve from 0.99121\n",
            "1875/1875 [==============================] - 127s 68ms/step - loss: 7.5073e-04 - accuracy: 0.9989 - val_loss: 0.0070 - val_accuracy: 0.9856\n",
            "40/40 [==============================] - 2s 23ms/step\n",
            "\n",
            "Fold Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00       104\n",
            "          FR       1.00      0.90      0.95       104\n",
            "          FT       0.97      1.00      0.99       104\n",
            "           L       1.00      1.00      1.00       104\n",
            "          LF       0.99      1.00      1.00       105\n",
            "          MN       0.97      1.00      0.99       105\n",
            "           O       0.98      1.00      0.99       104\n",
            "          PE       0.97      1.00      0.99       104\n",
            "          PO       1.00      1.00      1.00       105\n",
            "          SC       1.00      1.00      1.00       104\n",
            "          SE       1.00      0.97      0.99       104\n",
            "          US       0.99      1.00      1.00       104\n",
            "\n",
            "    accuracy                           0.99      1251\n",
            "   macro avg       0.99      0.99      0.99      1251\n",
            "weighted avg       0.99      0.99      0.99      1251\n",
            "\n",
            "\n",
            "Training Metrics: Accuracy: 0.9991999864578247\n",
            "Validation Metrics: Accuracy: 0.9912070631980896\n",
            "Testing Metrics: Accuracy: 0.9896082878112793\n",
            "\n",
            "Training Confusion Matrix:\n",
            "118/118 [==============================] - 3s 28ms/step\n",
            "[[312   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 309   0   0   0   2   0   0   0   0   1   0]\n",
            " [  0   0 313   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 313   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 312   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 312   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 312   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 313   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 312   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 313   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 313   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 313]]\n",
            "\n",
            "Validation Confusion Matrix:\n",
            "40/40 [==============================] - 1s 29ms/step\n",
            "[[105   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  96   0   0   0   2   1   2   1   0   2   1]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 104   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 104   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 105   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 104   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   0   0   0   0   2   0   0   0   0 102   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[104   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  94   3   0   1   0   2   3   0   0   0   1]\n",
            " [  0   0 104   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 104   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 105   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 104   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 105   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 104   0   0]\n",
            " [  0   0   0   0   0   3   0   0   0   0 101   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 104]]\n",
            "\n",
            "Fold 7\n",
            "Total 399968 word vectors in Glove 6B 100d.\n",
            "Hybrid LSTM-SVM Model\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 1000, 100)         155500    \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, 200)               160800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 12)                612       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 326962 (1.25 MB)\n",
            "Trainable params: 326962 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.5709\n",
            "Epoch 1: val_accuracy improved from -inf to 0.84093, saving model to model_rnn_fold_7.hdf5\n",
            "1875/1875 [==============================] - 135s 70ms/step - loss: 0.1340 - accuracy: 0.5709 - val_loss: 0.0762 - val_accuracy: 0.8409\n",
            "Epoch 2/15\n",
            "   2/1875 [..............................] - ETA: 1:47 - loss: 0.0326 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9160\n",
            "Epoch 2: val_accuracy improved from 0.84093 to 0.95204, saving model to model_rnn_fold_7.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0396 - accuracy: 0.9160 - val_loss: 0.0215 - val_accuracy: 0.9520\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9683\n",
            "Epoch 3: val_accuracy improved from 0.95204 to 0.95683, saving model to model_rnn_fold_7.hdf5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0162 - accuracy: 0.9683 - val_loss: 0.0169 - val_accuracy: 0.9568\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9808\n",
            "Epoch 4: val_accuracy improved from 0.95683 to 0.98082, saving model to model_rnn_fold_7.hdf5\n",
            "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0094 - accuracy: 0.9808 - val_loss: 0.0099 - val_accuracy: 0.9808\n",
            "Epoch 5/15\n",
            "1120/1875 [================>.............] - ETA: 45s - loss: 0.0070 - accuracy: 0.9862"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Input\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import LabelEncoder  # Import the LabelEncoder\n",
        "\n",
        "def clean_str(string):\n",
        "    string = re.sub(r\"\\\\\", \"\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "    string = re.sub(r\"\\\"\", \"\", string)\n",
        "    return string.strip().lower()\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "df = pd.read_csv('normalized_dataset.csv')\n",
        "\n",
        "# Oversample the minority classes\n",
        "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(df['normalized_requirements'].values.reshape(-1, 1), df['Type'])\n",
        "\n",
        "# Create a new DataFrame with balanced data\n",
        "df_balanced = pd.DataFrame({'Type': y_resampled, 'normalized_requirements': X_resampled.flatten()})\n",
        "\n",
        "df_balanced = df_balanced.dropna()\n",
        "df_balanced = df_balanced.reset_index(drop=True)\n",
        "\n",
        "print('Shape of dataset ', df_balanced.shape)\n",
        "print(df_balanced.columns)\n",
        "print('No. of unique classes', len(set(df_balanced['Type'])))\n",
        "macronum = sorted(set(df_balanced['Type']))\n",
        "macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n",
        "\n",
        "def fun(i):\n",
        "    return macro_to_id[i]\n",
        "\n",
        "df_balanced['Type'] = df_balanced['Type'].apply(fun)\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for idx in range(df_balanced.normalized_requirements.shape[0]):\n",
        "    text = BeautifulSoup(df_balanced.normalized_requirements[idx])\n",
        "    texts.append(clean_str(str(text.get_text().encode())))\n",
        "\n",
        "for idx in df_balanced['Type']:\n",
        "    labels.append(idx)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print('Number of Unique Tokens', len(word_index))\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of Data Tensor:', data.shape)\n",
        "print('Shape of Label Tensor:', labels.shape)\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder on the original labels\n",
        "original_labels = df['Type']\n",
        "label_encoder.fit(original_labels)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "fold_count = 0\n",
        "for train_index, test_index in skf.split(data, np.argmax(labels, axis=1)):\n",
        "    fold_count += 1\n",
        "    print(f\"\\nFold {fold_count}\")\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, stratify=y_train, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    embeddings_index = {}\n",
        "    with open('glove.6B.100d.txt', encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('#') or line.startswith('%'):\n",
        "                continue  # Skip header lines\n",
        "            if not line.strip():\n",
        "                continue  # Skip empty lines\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))\n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    embedding_layer = Embedding(len(word_index) + 1,\n",
        "                                EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=True)\n",
        "\n",
        "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "    l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
        "    dense_layer = Dense(50, activation='relu')(l_lstm)  # LSTM output connected to a dense layer\n",
        "    svm_output = Dense(len(macronum), activation='linear')(dense_layer)  # SVM output\n",
        "    model = Model(sequence_input, svm_output)\n",
        "    model.compile(loss='hinge',  # Hinge loss for SVM\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Hybrid LSTM-SVM Model\")\n",
        "    model.summary()\n",
        "\n",
        "    # Add EarlyStopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "    cp = ModelCheckpoint(f'model_rnn_fold_{fold_count}.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=15, batch_size=2, callbacks=[cp, early_stopping])\n",
        "\n",
        "    # Use the trained model to make predictions on the test set\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "    y_test_class = np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "    # Convert class indices back to original labels\n",
        "    y_test_original = label_encoder.inverse_transform(y_test_class)\n",
        "    y_pred_original = label_encoder.inverse_transform(y_pred_class)\n",
        "\n",
        "\n",
        "\n",
        "    # Evaluate the performance on the test set with original labels\n",
        "    print(\"\\nFold Results:\")\n",
        "    print(classification_report(y_test_original, y_pred_original))\n",
        "\n",
        "\n",
        "\n",
        "    # Print training, validation, and testing accuracy, precision, recall, and F1 score\n",
        "    train_metrics = model.evaluate(x_train, y_train, verbose=0)\n",
        "    val_metrics = model.evaluate(x_val, y_val, verbose=0)\n",
        "    test_metrics = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"\\nTraining Metrics: Accuracy: {train_metrics[1]}\")\n",
        "    print(f\"Validation Metrics: Accuracy: {val_metrics[1]}\")\n",
        "    print(f\"Testing Metrics: Accuracy: {test_metrics[1]}\")\n",
        "\n",
        "    print(\"\\nTraining Confusion Matrix:\")\n",
        "    print(confusion_matrix(np.argmax(y_train, axis=1), np.argmax(model.predict(x_train), axis=1)))\n",
        "\n",
        "    print(\"\\nValidation Confusion Matrix:\")\n",
        "    print(confusion_matrix(np.argmax(y_val, axis=1), np.argmax(model.predict(x_val), axis=1)))\n",
        "\n",
        "    print(\"\\nTesting Confusion Matrix:\")\n",
        "    print(confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txqF071tNL8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}